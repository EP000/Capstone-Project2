{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324a83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedc9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001TP_006690_L.png', '0001TP_006720_L.png', '0001TP_006750_L.png', '0001TP_006780_L.png', '0001TP_006810_L.png']\n",
      "['0001TP_006690.png', '0001TP_006720.png', '0001TP_006750.png', '0001TP_006780.png', '0001TP_006810.png']\n"
     ]
    }
   ],
   "source": [
    "label_path = './dataset/Labeled_data/'\n",
    "origin_path = './dataset/Original_data/'\n",
    "\n",
    "label_list = os.listdir(label_path)\n",
    "origin_list = os.listdir(origin_path)\n",
    "\n",
    "print(label_list[0:5])\n",
    "print(origin_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8536e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   3,   3, ...,   3,   3,   3],\n",
       "       [  3,   3,   3, ...,   3,   3,   3],\n",
       "       [  3,   3,   3, ...,   3,   3,   3],\n",
       "       ...,\n",
       "       [  1,   1,   1, ..., 255, 255, 255],\n",
       "       [  1,   1,   1, ..., 255, 255, 255],\n",
       "       [  1,   1,   1, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Image.open('./data_cap/Gray_data/train/0001TP_006690.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64ae73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Definitions\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# A list of all labels\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Please adapt the train IDs as appropriate for your approach.\n",
    "# Note that you might want to ignore labels with ID 255 during training.\n",
    "# Further note that the current train IDs are only a suggestion. You can use whatever you like.\n",
    "# Make sure to provide your results using the original IDs and not the training IDs.\n",
    "# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    \n",
    "    Label(  'Pole'                 ,  0 ,        0 , 'object'          , 0       , False        , True         , (  0,  0, 64) ),\n",
    "    Label(  'Pole'                 ,  1 ,        0 , 'object'          , 0       , False        , True         , (192,192,128) ),\n",
    "    Label(  'SignSymbol'           ,  2 ,        1 , 'object'          , 0       , False        , True         , (128,128, 64) ),\n",
    "    Label(  'SignSymbol'           ,  3 ,        1 , 'object'          , 0       , False        , True         , (192,128,128) ),\n",
    "    Label(  'SignSymbol'           ,  4 ,        1 , 'object'          , 0       , False        , True         , (  0, 64, 64) ),\n",
    "    \n",
    "    Label(  'Bicyclist'            ,  5 ,        2 , 'human'           , 1       , True         , False        , (  0,128,192) ),\n",
    "    Label(  'Bicyclist'            ,  6 ,        2 , 'human'           , 1       , True         , False        , (192,  0,192) ),\n",
    "    Label(  'Pedestrian'           ,  7 ,        3 , 'human'           , 1       , True         , False        , ( 64, 64,  0) ),\n",
    "    Label(  'Pedestrian'           ,  8 ,        3 , 'human'           , 1       , True         , False        , (192,128, 64) ),\n",
    "    Label(  'Pedestrian'           ,  9 ,        3 , 'human'           , 1       , True         , False        , ( 64,128, 64) ),\n",
    "    Label(  'Pedestrian'           , 10 ,        3 , 'human'           , 1       , True         , False        , ( 64,  0,192) ),\n",
    "    \n",
    "    Label(  'Building'             , 11 ,        4 , 'construction'    , 2       , False        , False        , ( 64,  0, 64) ),\n",
    "    Label(  'Building'             , 12 ,        4 , 'construction'    , 2       , False        , False        , (128,  0,  0) ),\n",
    "    Label(  'Building'             , 13 ,        4 , 'construction'    , 2       , False        , False        , (192,  0,128) ),\n",
    "    Label(  'Building'             , 14 ,        4 , 'construction'    , 2       , False        , False        , ( 64,192,  0) ),\n",
    "    Label(  'Building'             , 15 ,        4 , 'construction'    , 2       , False        , False        , (  0,128, 64) ),\n",
    "    Label(  'Fence'                , 16 ,        5 , 'construction'    , 2       , False        , False        , ( 64,128, 64) ),\n",
    "    \n",
    "    Label(  'Pavement'             , 17 ,        6 , 'flat'            , 3       , False        , False        , ( 64,192,128) ),\n",
    "    Label(  'Pavement'             , 18 ,        6 , 'flat'            , 3       , False        , False        , (128,128,192) ),\n",
    "    Label(  'Pavement'             , 19 ,        6 , 'flat'            , 3       , False        , False        , (  0,  0,192) ),\n",
    "    Label(  'Road'                 , 20 ,        7 , 'flat'            , 3       , False        , False        , (192,  0, 64) ),\n",
    "    \n",
    "    Label(  'Car'                  , 21 ,        8 , 'vehicle'         , 4       , True         , False        , ( 64,128,192) ),\n",
    "    Label(  'Car'                  , 22 ,        8 , 'vehicle'         , 4       , True         , False        , (128, 64, 64) ),\n",
    "    Label(  'Car'                  , 23 ,        8 , 'vehicle'         , 4       , True         , False        , (192,128,192) ),\n",
    "    Label(  'Car'                  , 24 ,        8 , 'vehicle'         , 4       , True         , False        , ( 64,  0,128) ),\n",
    "    \n",
    "    Label(  'Sky'                  , 25 ,        9 , 'sky'             , 5       , False        , False        , (128,128,128) ),\n",
    "    \n",
    "    Label(  'Tree'                 , 26 ,       10 , 'nature'          , 6       , False        , False        , (192,192,  0) ),\n",
    "    Label(  'Tree'                 , 27 ,       10 , 'nature'          , 6       , False        , False        , (128,128,  0) ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcfd3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel2id = {' '.join(map(str, label.color)): label.trainId for label in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa25157",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_path = './data_cap/gray_data2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67c8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 701/701 [37:19<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(label_list):\n",
    "    img = np.array(Image.open(label_path + p))\n",
    "    ret = np.array([[pixel2id[' '.join(map(str, pixel))] if ' '.join(map(str, pixel)) in pixel2id else 11 for pixel in row] for row in img], dtype=np.uint8)\n",
    "    Image.fromarray(ret).save(new_label_path  + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2078b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "train = []\n",
    "f = open(\"./dataset/train.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    train.append(line.split('\\n')[0]+'_L.png')\n",
    "f.close()\n",
    "\n",
    "val = []\n",
    "f = open(\"./dataset/val.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    val.append(line.split('\\n')[0]+'_L.png')\n",
    "f.close()\n",
    "\n",
    "test = []\n",
    "f = open(\"./dataset/test.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    test.append(line.split('\\n')[0]+'_L.png')\n",
    "f.close()\n",
    "\n",
    "\n",
    "for move_f in train:\n",
    "    shutil.copy('./data_cap/gray_data2/'+move_f, './data_cap/gray_data2/train/'+move_f)\n",
    "    \n",
    "for move_f in val:\n",
    "    shutil.copy('./data_cap/gray_data2/'+move_f, './data_cap/gray_data2/val/'+move_f)\n",
    "\n",
    "for move_f in test:\n",
    "    shutil.copy('./data_cap/gray_data2/'+move_f, './data_cap/gray_data2/test/'+move_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24d916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
