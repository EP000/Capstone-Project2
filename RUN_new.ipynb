{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### package load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from model_new import convert_bn_to_instancenorm, convert_bn_to_evonorm, convert_bn_to_groupnorm, DeepLabHead \n",
    "from helpers import AverageMeter, ProgressMeter, iouCalc, visim, vislbl\n",
    "from labels import labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data_norm_v2.npz') ## or 'data_origin.npz' 원본 or norm ver :: 모델 결과 확인 후 결정\n",
    "\n",
    "train_x = npzfile['train_x']\n",
    "train_y = npzfile['train_y']\n",
    "val_x = npzfile['val_x']\n",
    "val_y = npzfile['val_y']\n",
    "test_x = npzfile['test_x']\n",
    "test_y = npzfile['test_y']\n",
    "\n",
    "npzfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLab v3 ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False).to(device)\n",
    "         # dlv3 backbone resnoet 50 :: output chnnel: 2048 --> DL input channel :: 2048\n",
    "model.classifier = DeepLabHead(2048, 12).to(device) # 12 = class num\n",
    "   # 작동되는 지 확인 필요 (개수 맞추기)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "best_miou = 0.0\n",
    "metrics = {'train_loss' : [],\n",
    "           'train_acc' : [],\n",
    "           'test_acc' : [],\n",
    "           'test_loss' : [],\n",
    "           'miou' : []}\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of class names\n",
    "  # classLabels: label명\n",
    "  # validClasses: label에 해당하는 id값\n",
    "\n",
    "classLabels = []\n",
    "for label in labels:\n",
    "    if label.name not in classLabels:\n",
    "        classLabels.append(label.name)\n",
    "classLabels.append('void')\n",
    "\n",
    "validClasses = list(\n",
    "    np.unique(\n",
    "        [label.id for label in labels \n",
    "         if label.id >= 0\n",
    "        ] + [11]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter\n",
    "\n",
    "batch_size = 2\n",
    "num_epoch = 50\n",
    "\n",
    "result_dir = os.getcwd() + '/result/' + 'new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "   # X: 0~255, RGB값 가지는 이미지 데이터 (560, 720, 960, 3)\n",
    "   # Y: 0~11 label값 가지는 픽셀당 클래스 데이터 (560, 720, 960)\n",
    "X = torch.tensor(train_x, dtype=torch.float32)\n",
    "Y = torch.tensor(train_y, dtype=torch.long)\n",
    "\n",
    "data = TensorDataset(X.permute(dims=(0, 3, 1, 2)), Y)\n",
    "train_data = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 3350644,\n",
       " '1': 3682379,\n",
       " '2': 1888603,\n",
       " '3': 2478108,\n",
       " '4': 81471634,\n",
       " '5': 4996800,\n",
       " '6': 23813698,\n",
       " '7': 98899475,\n",
       " '8': 16468486,\n",
       " '9': 53441175,\n",
       " '10': 37943059,\n",
       " '11': 10253939}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create class weight\n",
    "label_num = {str(_id): 0 for _id in validClasses}\n",
    "label_num\n",
    "\n",
    "for y in train_y.flatten():\n",
    "    label_num[str(y)] += 1\n",
    "label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete void -- max value\n",
    "max_num = max([v for k, v in label_num.items() if k != '11'])\n",
    "weights = [max_num/num for key, num in label_num.items()]\n",
    "\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights, ignore_index=12) # weight 파라미터에 class_weight 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29.5166, 26.8575, 52.3665, 39.9093,  1.2139, 19.7926,  4.1530,  1.0000,\n",
       "         6.0054,  1.8506,  2.6065,  9.6450])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                               | 1/245 [00:17<1:10:18, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.5794e+00 (2.5794e+00)\tAccuracy 0.104 (0.104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                               | 2/245 [00:34<1:09:18, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.4892e+00 (2.5343e+00)\tAccuracy 0.109 (0.107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                               | 3/245 [00:51<1:10:04, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.3870e+00 (2.4852e+00)\tAccuracy 0.183 (0.132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▎                                                                              | 4/245 [01:09<1:10:09, 17.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.3898e+00 (2.4613e+00)\tAccuracy 0.221 (0.154)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                              | 5/245 [01:27<1:09:58, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.3405e+00 (2.4372e+00)\tAccuracy 0.207 (0.165)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▉                                                                              | 6/245 [01:44<1:10:11, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.1151e+00 (2.3835e+00)\tAccuracy 0.278 (0.184)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                             | 7/245 [02:02<1:10:03, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.0720e+00 (2.3390e+00)\tAccuracy 0.282 (0.198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                             | 8/245 [02:20<1:09:45, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.8558e+00 (2.2786e+00)\tAccuracy 0.321 (0.213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                             | 9/245 [02:37<1:09:07, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.8242e+00 (2.2281e+00)\tAccuracy 0.305 (0.223)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                           | 10/245 [02:55<1:08:44, 17.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.6717e+00 (2.1725e+00)\tAccuracy 0.337 (0.235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▌                                                                           | 11/245 [03:13<1:09:02, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.4842e+00 (2.1099e+00)\tAccuracy 0.316 (0.242)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▊                                                                           | 12/245 [03:30<1:08:42, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.7307e+00 (2.0783e+00)\tAccuracy 0.406 (0.256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████▏                                                                          | 13/245 [03:48<1:08:30, 17.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.7778e+00 (2.0552e+00)\tAccuracy 0.379 (0.265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▌                                                                          | 14/245 [04:06<1:08:14, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.6881e+00 (2.0289e+00)\tAccuracy 0.387 (0.274)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                          | 15/245 [04:23<1:07:40, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.5651e+00 (1.9980e+00)\tAccuracy 0.464 (0.287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▏                                                                         | 16/245 [04:41<1:07:23, 17.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.4345e+00 (1.9628e+00)\tAccuracy 0.391 (0.293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▍                                                                         | 17/245 [04:59<1:07:26, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 2.5302e+00 (1.9962e+00)\tAccuracy 0.572 (0.310)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                         | 18/245 [05:17<1:07:15, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.2788e+00 (1.9563e+00)\tAccuracy 0.615 (0.326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▏                                                                        | 19/245 [05:34<1:06:35, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, epoch: [0][  0/245]\tLoss 1.5987e+00 (1.9375e+00)\tAccuracy 0.605 (0.341)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "res = X.shape[1] * X.shape[2] # 720 * 960\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    loss_running = AverageMeter('Loss', ':.4e')\n",
    "    acc_running = AverageMeter('Accuracy', ':.3f')\n",
    "    \n",
    "    iou = iouCalc(classLabels, validClasses, voidClass = 11)\n",
    "    progress = ProgressMeter(\n",
    "        len(train_data),\n",
    "        [loss_running, acc_running],\n",
    "        prefix=\"Train, epoch: [{}]\".format(epoch))\n",
    "    \n",
    "    batch_loss = 0.0\n",
    "    for batch, (x, y) in enumerate(tqdm(train_data, total=len(train_data))):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(x)\n",
    "        outputs = outputs['out']\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        \n",
    "        # cross-entropy loss\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        bs = x.size(0)\n",
    "        loss = loss.item()\n",
    "        loss_running.update(loss, bs)\n",
    "        corrects = torch.sum((preds == y) & (y != 12))\n",
    "        \n",
    "        nvoid = int((y==12).sum()) \n",
    "        acc = corrects.double()/(bs*res-nvoid)\n",
    "        acc_running.update(acc, bs)\n",
    "        \n",
    "        # Calculate IoU scores of current batch\n",
    "        iou.evaluateBatch(preds, y)\n",
    "        \n",
    "        progress.display(epoch)\n",
    "        \n",
    "        \n",
    "    scheduler.step(loss_running.avg)\n",
    "    miou = iou.outputScores()\n",
    "    \n",
    "    # save checkpoint\n",
    "    now = datetime.datetime.now()\n",
    "    now_time = now.strftime('%y%m%d%H')\n",
    "    \n",
    "    # save path\n",
    "    if not os.path.isdir(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    \n",
    "    save_path = result_dir\n",
    "    \n",
    "    with open(save_path + 'train_logs.csv', 'a') as epochs:\n",
    "            epochs.write('{}, {:.4f}, {:.4f}, {:.4f}\\n'.format(\n",
    "                    epoch+1, loss_running.avg, acc_running.avg, miou))\n",
    "            \n",
    "    # Save model to file\n",
    "    torch.save({\n",
    "        'epoch' : epoch + 1,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_miou': best_miou,\n",
    "        'metrics': metrics,\n",
    "        }, save_path + now_time + '_E' + str(epoch+1) + '_checkpoint.pth.tar')\n",
    "    \n",
    "    # Save best model to file\n",
    "    if miou > best_miou:\n",
    "        print('mIoU improved from {:.4f} to {:.4f}.'.format(best_miou, miou))\n",
    "        best_miou = miou\n",
    "        \n",
    "    print('epoch ', epoch)\n",
    "    print('loss : {:.4f}   acc : {:.4f}   miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(val_x, dtype=torch.float32)\n",
    "Y = torch.tensor(val_y, dtype=torch.long)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(X.permute(dims=(0, 3, 1, 2)), Y)\n",
    "\n",
    "val_data = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "save_path = result_dir\n",
    "result = sorted(os.listdir(save_path), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch, file in enumerate(result[1:]):\n",
    "    checkpoint = torch.load(save_path + file)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    loss_running = AverageMeter('Loss', ':.4e')\n",
    "    acc_running = AverageMeter('Accuracy', ':.3f')\n",
    "    \n",
    "    iou = iouCalc(classLabels, validClasses, voidClass = 11)\n",
    "    \n",
    "    batch_loss = 0.0\n",
    "    \n",
    "    for batch, (x, y) in enumerate(tqdm(val_data, total=len(val_data))):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(x)\n",
    "        outputs = outputs['out']\n",
    "\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "\n",
    "        # cross-entropy loss\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Statistics\n",
    "        bs = x.size(0)\n",
    "        loss = loss.item()\n",
    "        loss_running.update(loss, bs)\n",
    "        corrects = torch.sum((preds == y) & (y != 12))\n",
    "\n",
    "        nvoid = int((y==12).sum())\n",
    "        acc = corrects.double()/(bs*res-nvoid)\n",
    "        acc_running.update(acc, bs)\n",
    "    \n",
    "        # Calculate IoU scores of current batch\n",
    "        iou.evaluateBatch(preds, y)\n",
    "\n",
    "    miou = iou.outputScores()\n",
    "    \n",
    "    with open(save_path + 'val_logs.csv', 'a') as epochs:\n",
    "            epochs.write('{}, {:.4f}, {:.4f}, {:.4f}\\n'.format(\n",
    "                    epoch+1, loss_running.avg, acc_running.avg, miou))\n",
    "    \n",
    "    print('val- epoch: {}'.format(epoch+1))\n",
    "    print('loss : {:.4f} acc : {:.4f} miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = pd.read_csv(save_path + 'train_logs.csv', names = ['epoch', 'loss', 'accuracy', 'miou'])\n",
    "val_logs = pd.read_csv(save_path + 'val_logs.csv', names = ['epoch', 'loss', 'accuracy', 'miou'])\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_logs['epoch'], train_logs['miou'], label = 'train_miou')\n",
    "plt.plot(train_logs['epoch'], train_logs['accuracy'], label = 'train_accuracy')\n",
    "\n",
    "plt.plot(val_logs['epoch'], val_logs['miou'], label = 'val_miou')\n",
    "plt.plot(val_logs['epoch'], val_logs['accuracy'], label = 'val_accuracy')\n",
    "\n",
    "plt.xticks([i for i in range(1, train_logs.shape[0]+1)])\n",
    "plt.title(\"Performances of train, val dataset\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(test_x, dtype=torch.float32)\n",
    "Y = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(X.permute(dims=(0, 3, 1, 2)), Y)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#save_path = result_dir\n",
    "#result = sorted(os.listdir(save_path), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0605_best_weights.pth.tar']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(save_path + result[2]) # train, val 결과보고 결정 (overfitting 시작되기 전)\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_time = AverageMeter('Time', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "progress = ProgressMeter(\n",
    "    len(test_data),\n",
    "    [batch_time, data_time],\n",
    "    prefix='Predict: ')\n",
    "loss_running = AverageMeter('Loss', ':.4e')\n",
    "acc_running = AverageMeter('Accuracy', ':.3f')\n",
    "    \n",
    "iou = iouCalc(classLabels, validClasses, voidClass = 11)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "batch_loss = 0.0\n",
    "for batch, (x, y) in enumerate(tqdm(test_data, total=len(test_data))):\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward\n",
    "    outputs = model(x)\n",
    "    outputs = outputs['out']\n",
    "\n",
    "    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "    # cross-entropy loss\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    # Statistics\n",
    "    bs = x.size(0)\n",
    "    loss = loss.item()\n",
    "    loss_running.update(loss, bs)\n",
    "    corrects = torch.sum((preds == y) & (y != 12))\n",
    "\n",
    "    nvoid = int((y==12).sum())\n",
    "    acc = corrects.double()/(bs*res-nvoid)\n",
    "    acc_running.update(acc, bs)\n",
    "\n",
    "    # Calculate IoU scores of current batch\n",
    "    iou.evaluateBatch(preds, y)\n",
    "\n",
    "miou = iou.outputScores()\n",
    "\n",
    "print('loss : {:.4f} acc : {:.4f} miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yooso",
   "language": "python",
   "name": "yooso_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
