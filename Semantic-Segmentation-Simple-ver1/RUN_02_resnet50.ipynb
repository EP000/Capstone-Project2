{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2a6992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from labels import labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5811de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로\n",
    "#  os.getcwd() :'/home/ag/Capstone2/DeepLab_V3_ver1'\n",
    "origin_data_path = os.getcwd() + '/data/Original_data/'\n",
    "labeled_data_path = os.getcwd() + '/data/Labeled_data/'\n",
    "\n",
    "origin_data_list = os.listdir(origin_data_path) # x\n",
    "labeled_data_list = os.listdir(labeled_data_path) # y\n",
    "\n",
    "# 파일명 랜덤\n",
    "random.shuffle(origin_data_list)\n",
    "random.shuffle(labeled_data_list)\n",
    "\n",
    "# train, test / x, y \n",
    "train_x_file = origin_data_list[:int(len(origin_data_list)*0.8)]\n",
    "train_y_file = [file_name[:-4] + '_L.png' for file_name in train_x_file]\n",
    "\n",
    "test_x_file = [file_name for file_name in origin_data_list if file_name not in train_x_file]\n",
    "test_y_file = [file_name[:-4] + '_L.png' for file_name in test_x_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca295aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 141 560 141\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x_file), len(test_x_file), len(train_y_file), len(test_y_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b80b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq05VD_f02220.png 0016E5_08107.png Seq05VD_f02220_L.png 0016E5_08107_L.png\n"
     ]
    }
   ],
   "source": [
    "print(train_x_file[0], test_x_file[0], train_y_file[0], test_y_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67ed5e",
   "metadata": {},
   "source": [
    "### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62db6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [np.array(Image.open(origin_data_path + train)) for train in train_x_file]\n",
    "test_x = [np.array(Image.open(origin_data_path + test)) for test in test_x_file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd0109",
   "metadata": {},
   "source": [
    "### Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351dbc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color to label catId\n",
    "color2label = { label.color   : label.id for label in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a95c59a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 560/560 [21:43<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "for file_name in tqdm(train_y_file):\n",
    "    image = np.array(Image.open(labeled_data_path + file_name))\n",
    "    ret = [[color2label[tuple([r[0], r[1], r[2]])] \n",
    "            if tuple([r[0], r[1], r[2]]) in color2label else 11\n",
    "            for r in row] \n",
    "           for row in image]\n",
    "    train_y.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38587377",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [05:28<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "test_y = []\n",
    "for file_name in tqdm(test_y_file):\n",
    "    image = np.array(Image.open(labeled_data_path + file_name))\n",
    "    ret = [[color2label[tuple([r[0], r[1], r[2]])] \n",
    "            if tuple([r[0], r[1], r[2]]) in color2label else 11\n",
    "            for r in row] \n",
    "           for row in image]\n",
    "    test_y.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fa0577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560, 720, 960), (141, 720, 960))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_y).shape, np.array(test_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88c21514",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d5781",
   "metadata": {},
   "source": [
    "### data save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2642672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez('data.npz', train_x=train_x, train_y=train_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b974d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada08c10",
   "metadata": {},
   "source": [
    "### package load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db262e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7374e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import convert_bn_to_instancenorm, convert_bn_to_evonorm, convert_bn_to_groupnorm, DeepLabHead, UNet\n",
    "from helpers import AverageMeter, ProgressMeter, iouCalc, visim, vislbl\n",
    "from labels import labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e531816",
   "metadata": {},
   "source": [
    "### CPU or GPU\n",
    "#### 아래 코드에서 True이면 GPU 사용, False 이면 CPU 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e11a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available() and True \n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26ad9e",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295e0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data.npz')\n",
    "\n",
    "train_x = npzfile['train_x']\n",
    "train_y = npzfile['train_y']\n",
    "test_x = npzfile['test_x']\n",
    "test_y = npzfile['test_y']\n",
    "\n",
    "npzfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684bea5",
   "metadata": {},
   "source": [
    "### DeepLab v3 ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7757fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=False).to(device)\n",
    "model.classifier = DeepLabHead(2048, 12).to(device) # 12 = class num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202574db",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2) # 파라미터 학습속도 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ea1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics\n",
    "best_miou = 0.0\n",
    "metrics = {'train_loss' : [],\n",
    "           'train_acc' : [],\n",
    "           'test_acc' : [],\n",
    "           'test_loss' : [],\n",
    "           'miou' : []}\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71edf0",
   "metadata": {},
   "source": [
    "### Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61074ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of class names\n",
    "classLabels = []\n",
    "for label in labels:\n",
    "    if label.name not in classLabels:\n",
    "        classLabels.append(label.name)\n",
    "classLabels.append('void')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d3f8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validClasses = list(np.unique([label.id for label in labels if label.id >= 0] + [11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755588d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 'Pole', 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classLabels), len(validClasses), classLabels[0], validClasses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc84a4",
   "metadata": {},
   "source": [
    "### train / validataion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ef0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_x[:int(train_x.shape[0]*0.875)], dtype=torch.float32)\n",
    "train_Y = torch.tensor(train_y[:int(train_y.shape[0]*0.875)], dtype=torch.long)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_X.permute(dims=(0, 3, 1, 2)), train_Y)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ec006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = torch.tensor(train_x[int(train_x.shape[0]*0.875):], dtype=torch.float32)\n",
    "val_Y = torch.tensor(train_y[int(train_x.shape[0]*0.875):], dtype=torch.long)\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(val_X.permute(dims=(0, 3, 1, 2)), val_Y)\n",
    "\n",
    "val_data = torch.utils.data.DataLoader(val_data, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df632881",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = {i:(train_Y == i).sum().tolist() for i in range(12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5183847",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1/dist[i] for i in range(12)]\n",
    "total_weights = sum(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e8d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = torch.FloatTensor([w/total_weights for w in weights]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weight, ignore_index=12) # weight 파라미터에 class_weight 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07d3d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "res = train_X.shape[1] * train_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da32590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691200, 691200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape[1] * train_X.shape[2], val_X.shape[1] * val_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61026c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [04:03<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.373\n",
      "SignSymbol    : 0.587\n",
      "Bicyclist     : 0.667\n",
      "Pedestrian    : 0.553\n",
      "Building      : 0.844\n",
      "Fence         : 0.741\n",
      "Pavement      : 0.830\n",
      "Road          : 0.950\n",
      "Car           : 0.866\n",
      "Sky           : 0.900\n",
      "Tree          : 0.814\n",
      "---------------------\n",
      "Mean IoU      : 0.739\n",
      "---------------------\n",
      "train epoch  1\n",
      "loss : 0.2871   acc : 0.9082   miou : 0.7388\n",
      "mIoU improved from 0.7367 to 0.7388.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [04:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.392\n",
      "SignSymbol    : 0.612\n",
      "Bicyclist     : 0.683\n",
      "Pedestrian    : 0.589\n",
      "Building      : 0.853\n",
      "Fence         : 0.760\n",
      "Pavement      : 0.842\n",
      "Road          : 0.954\n",
      "Car           : 0.875\n",
      "Sky           : 0.904\n",
      "Tree          : 0.824\n",
      "---------------------\n",
      "Mean IoU      : 0.753\n",
      "---------------------\n",
      "train epoch  2\n",
      "loss : 0.2536   acc : 0.9141   miou : 0.7534\n",
      "mIoU improved from 0.7388 to 0.7534.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [04:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.421\n",
      "SignSymbol    : 0.653\n",
      "Bicyclist     : 0.737\n",
      "Pedestrian    : 0.629\n",
      "Building      : 0.873\n",
      "Fence         : 0.791\n",
      "Pavement      : 0.857\n",
      "Road          : 0.959\n",
      "Car           : 0.889\n",
      "Sky           : 0.908\n",
      "Tree          : 0.840\n",
      "---------------------\n",
      "Mean IoU      : 0.778\n",
      "---------------------\n",
      "train epoch  3\n",
      "loss : 0.2190   acc : 0.9235   miou : 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/245 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIoU improved from 0.7534 to 0.7779.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [04:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.438\n",
      "SignSymbol    : 0.677\n",
      "Bicyclist     : 0.751\n",
      "Pedestrian    : 0.647\n",
      "Building      : 0.883\n",
      "Fence         : 0.811\n",
      "Pavement      : 0.865\n",
      "Road          : 0.963\n",
      "Car           : 0.896\n",
      "Sky           : 0.911\n",
      "Tree          : 0.848\n",
      "---------------------\n",
      "Mean IoU      : 0.790\n",
      "---------------------\n",
      "train epoch  4\n",
      "loss : 0.1988   acc : 0.9289   miou : 0.7900\n",
      "mIoU improved from 0.7779 to 0.7900.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [04:05<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.456\n",
      "SignSymbol    : 0.690\n",
      "Bicyclist     : 0.759\n",
      "Pedestrian    : 0.661\n",
      "Building      : 0.890\n",
      "Fence         : 0.817\n",
      "Pavement      : 0.875\n",
      "Road          : 0.966\n",
      "Car           : 0.902\n",
      "Sky           : 0.913\n",
      "Tree          : 0.852\n",
      "---------------------\n",
      "Mean IoU      : 0.798\n",
      "---------------------\n",
      "train epoch  5\n",
      "loss : 0.1880   acc : 0.9325   miou : 0.7982\n",
      "mIoU improved from 0.7900 to 0.7982.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    model.train()\n",
    "    \n",
    "    # batch_time = AverageMeter('Time', ':6.3f')\n",
    "    # data_time = AverageMeter('Data', ':6.3f')\n",
    "    loss_running = AverageMeter('Loss', ':.4e')\n",
    "    acc_running = AverageMeter('Accuracy', ':.3f')  \n",
    "    iou = iouCalc(classLabels, validClasses, voidClass = 11)\n",
    "    progress = ProgressMeter(\n",
    "        len(train_data),\n",
    "        [loss_running, acc_running],\n",
    "        prefix=\"Train, epoch: [{}]\".format(epoch))\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    for batch, (x, y) in enumerate(tqdm(train_data, total=len(train_data))):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(x)\n",
    "        outputs = outputs['out']\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        \n",
    "        # cross-entropy loss\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        bs = x.size(0)\n",
    "        loss = loss.item()\n",
    "        loss_running.update(loss, bs)\n",
    "        corrects = torch.sum((preds == y) & (y != 12))\n",
    "        \n",
    "        nvoid = int((y==12).sum())\n",
    "        acc = corrects.double()/(bs*res-nvoid)\n",
    "        acc_running.update(acc, bs)\n",
    "        \n",
    "        # Calculate IoU scores of current batch\n",
    "        iou.evaluateBatch(preds, y)\n",
    "        \n",
    "#         progress.display(batch)\n",
    "        \n",
    "     \n",
    "    scheduler.step(loss_running.avg)\n",
    "    miou = iou.outputScores()\n",
    "    \n",
    "    print('train epoch ', epoch+1)\n",
    "    print('loss : {:.4f}   acc : {:.4f}   miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou))\n",
    "    \n",
    "    # save checkpoint per epoch\n",
    "    now = datetime.datetime.now()\n",
    "    now_time = now.strftime('%y%m%d_%H:%M')\n",
    "    \n",
    "    # save path\n",
    "    if not os.path.isdir(os.getcwd() + '/result'):\n",
    "        os.makedirs(os.getcwd() + '/result')\n",
    "    \n",
    "    save_path = os.getcwd() + '/result/'\n",
    "    \n",
    "    # Save best model to file\n",
    "    torch.save({\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_miou': best_miou,\n",
    "        'metrics': metrics,\n",
    "        }, save_path + now_time + '_checkpoint.pth.tar')\n",
    "    \n",
    "    # Save best model to file\n",
    "    if miou > best_miou:\n",
    "        print('mIoU improved from {:.4f} to {:.4f}.'.format(best_miou, miou))\n",
    "        best_miou = miou\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, save_path + now_time + '_best_weights.pth.tar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99899f98",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf16deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(test_x, dtype=torch.float32)\n",
    "Y = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "data = torch.utils.data.TensorDataset(X.permute(dims=(0, 3, 1, 2)), Y)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b47707c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "\n",
    "# save path\n",
    "if not os.path.isdir(os.getcwd() + '/result'):\n",
    "    os.makedirs(os.getcwd() + '/result')\n",
    "\n",
    "save_path = os.getcwd() + '/result/'\n",
    "result = sorted(os.listdir(save_path), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1213154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model weights (epoch 4) from /home/ag/Capstone2/TEST/result/210602_18:58_best_weights.pth.tar\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(save_path + result[1]) # 가장 최신 best_weights 파일 가져옴\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "print('Loaded best model weights (epoch {}) from {}'.format(checkpoint['epoch'], save_path + result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ff5133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:15<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes           IoU\n",
      "---------------------\n",
      "Pole          : 0.444\n",
      "SignSymbol    : 0.655\n",
      "Bicyclist     : 0.749\n",
      "Pedestrian    : 0.642\n",
      "Building      : 0.887\n",
      "Fence         : 0.800\n",
      "Pavement      : 0.866\n",
      "Road          : 0.965\n",
      "Car           : 0.896\n",
      "Sky           : 0.914\n",
      "Tree          : 0.846\n",
      "---------------------\n",
      "Mean IoU      : 0.788\n",
      "---------------------\n",
      "loss : 0.2247 acc : 0.9292 miou : 0.7876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_time = AverageMeter('Time', ':6.3f')\n",
    "data_time = AverageMeter('Data', ':6.3f')\n",
    "progress = ProgressMeter(\n",
    "    len(test_data),\n",
    "    [batch_time, data_time],\n",
    "    prefix='Predict: ')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "batch_loss = 0.0\n",
    "for batch, (x, y) in enumerate(tqdm(test_data, total=len(test_data))):\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward\n",
    "    outputs = model(x)\n",
    "    outputs = outputs['out']\n",
    "\n",
    "    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "    # cross-entropy loss\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    # Statistics\n",
    "    bs = x.size(0)\n",
    "    loss = loss.item()\n",
    "    loss_running.update(loss, bs)\n",
    "    corrects = torch.sum((preds == y) & (y != 12))\n",
    "\n",
    "    nvoid = int((y==12).sum())\n",
    "    acc = corrects.double()/(bs*res-nvoid)\n",
    "    acc_running.update(acc, bs)\n",
    "\n",
    "    # Calculate IoU scores of current batch\n",
    "    iou.evaluateBatch(preds, y)\n",
    "\n",
    "miou = iou.outputScores()\n",
    "scheduler.step(loss_running.avg)\n",
    "\n",
    "print('loss : {:.4f} acc : {:.4f} miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a3962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a512f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd399f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ec38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validataion\n",
    "model.eval()\n",
    "\n",
    "loss_running = AverageMeter('Loss', ':.4e')\n",
    "acc_running = AverageMeter('Accuracy', ':.3f')\n",
    "iou = iouCalc(classLabels, validClasses, voidClass = 11)\n",
    "\n",
    "batch_loss = 0.0\n",
    "for batch, (x, y) in enumerate(tqdm(val_data, total=len(val_data))):\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward\n",
    "    outputs = model(x)\n",
    "    outputs = outputs['out']\n",
    "\n",
    "    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "    # cross-entropy loss\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    # Statistics\n",
    "    bs = x.size(0)\n",
    "    loss = loss.item()\n",
    "    loss_running.update(loss, bs)\n",
    "    corrects = torch.sum((preds == y) & (y != 12))\n",
    "\n",
    "    nvoid = int((y==12).sum())\n",
    "    acc = corrects.double()/(bs*res-nvoid)\n",
    "    acc_running.update(acc, bs)\n",
    "\n",
    "    # Calculate IoU scores of current batch\n",
    "    iou.evaluateBatch(preds, y)\n",
    "\n",
    "miou = iou.outputScores()\n",
    "\n",
    "# Reduce learning rate\n",
    "scheduler.step(loss_running.avg) \n",
    "\n",
    "print('validataion')\n",
    "print('loss : {:.4f}   acc : {:.4f}   miou : {:.4f}'.format(loss_running.avg, acc_running.avg, miou))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cap",
   "language": "python",
   "name": "venv_cap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
